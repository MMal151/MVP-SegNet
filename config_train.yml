# If false, CPU will be utilised instead of GPU.
alw_parallel_processing: True
gpu: "0,1" # Comma-seperated list of GPUs that can be used.
loader:
  csv_path: "DataFiles/Local_Set/" # Path for test/train/valid csv files. [Suggested: Run prepare dataset mode to generate CSV files.]
data:
  input_shape: "(128, 128, 128)" # If patching is applied, then input shape = patch_shape
  batch_size: 1
  normalize_img: True
  normalize:
    technique: 'default'  # Possible Values: 'default' - Standardization, 'greyscale' - Contrast Stretching
  shuffle: True # Shuffle dataset on each epoch, only applicable for training.
  steps_per_epoch: # If, -1 default value will be used. Default value: len(x) / batch_size
    train: 200
    valid: 100
    test: 100
# Possible Values: unet (U-Net 3D), vnet (V-Net), mvp
model_type: "mvp"
resume_train: True
load_path: "" # Load model from this file.
save_path: "" # Save model to this naming structure.
save_best_only: True
epochs: 200
# Apply early stopping when training.
aply_early_stpng: True
es: # Configurations for early stopping, only check if above parameter is True.
  monitor: 'val_loss' # Validation Loss
  patience: 15
  min_delta: 0.005
  mode: 'min'
  restore_best_weights: False # Restore best weights
  # Currently supporting: acc (Accuracy), mean_iou (Mean Intersection over Union), dice-coef (Dice Coefficient),
  # recall (Recall), and prec (Precision).
perf_metrics: "recall, prec, mean_iou, dice_coef"
# Possible values: adam, sgd, rmsprop, adadelta, adamax, adagrad
optimizer: "adam"
learning_rate: 0.001
 # Whether to use learning rate schedular or not. Configurations can be defined in ConfigurationFiles/LearningSchedularConfig
aply_lr_sch: False
loss: "focal_tversky"
  # Possible values: leakyrelu, relu, snake, gelu, prelu
activation: "prelu"
